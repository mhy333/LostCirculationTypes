{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5974ed",
   "metadata": {},
   "source": [
    "# 1.Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df66648a",
   "metadata": {},
   "source": [
    "# 1.1 Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f264c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.stats import wasserstein_distance\n",
    "import os\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman' \n",
    "plt.rcParams['font.size'] = 20                 \n",
    "plt.rcParams['font.weight'] = 'bold'            \n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['axes.labelweight'] = 'bold'       \n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.titleweight'] = 'bold'        \n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['legend.title_fontsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['axes.unicode_minus'] = False       \n",
    "\n",
    "# Create directory for plots\n",
    "plot_dir = \"E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/fill/\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# ========== Load Data ========== #\n",
    "df = pd.read_csv(\"E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_en.csv\")\n",
    "\n",
    "# ========== Select Numeric Columns with Missing Rate < 80% ========== #\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "missing_info = df[numeric_cols].isna().mean()\n",
    "to_impute_cols = missing_info[(missing_info > 0) & (missing_info < 0.8)].index.tolist()\n",
    "\n",
    "# ========== Visualize Missing Rates ========== #\n",
    "plt.figure(figsize=(10, 7))\n",
    "sorted_missing = missing_info[to_impute_cols].sort_values(ascending=False)\n",
    "bars = plt.barh(sorted_missing.index, sorted_missing.values, color='steelblue')\n",
    "plt.title(\"Missing Rate of Numerical Features\", fontweight='bold')\n",
    "plt.xlabel(\"Missing Rate\", fontweight='bold')\n",
    "plt.ylabel(\"Numerical Features\", fontweight='bold')\n",
    "\n",
    "# Annotate missing rate values\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.001, bar.get_y() + bar.get_height() / 1,\n",
    "             f\"{width:.2%}\", va='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/fill/missing_rates.png\",dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ========== Distribution Comparison and Imputation ========== #\n",
    "best_methods = {}\n",
    "imputed_df = df.copy()\n",
    "\n",
    "def get_decimal_places(series):\n",
    "    \"\"\" Get max number of decimal places in a series \"\"\"\n",
    "    return series.dropna().apply(lambda x: len(str(x).split('.')[1]) if '.' in str(x) else 0).max()\n",
    "\n",
    "def is_integer(series):\n",
    "    \"\"\" Check if all values in the series are integers \"\"\"\n",
    "    return series.dropna().apply(lambda x: float(x).is_integer()).all()\n",
    "\n",
    "def plot_distribution_comparison(feature):\n",
    "    original = df[feature].dropna()\n",
    "\n",
    "    decimal_places = get_decimal_places(original)\n",
    "    is_int = is_integer(original)\n",
    "\n",
    "    # Mean Imputation\n",
    "    mean_filled = df[feature].copy()\n",
    "    mean_filled.fillna(mean_filled.mean(), inplace=True)\n",
    "\n",
    "    # Median Imputation\n",
    "    median_filled = df[feature].copy()\n",
    "    median_filled.fillna(median_filled.median(), inplace=True)\n",
    "\n",
    "    # KNN Imputation\n",
    "    df_knn = df[numeric_cols].copy()\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    knn_filled_array = imputer.fit_transform(df_knn)\n",
    "    knn_filled_df = pd.DataFrame(knn_filled_array, columns=numeric_cols)\n",
    "    knn_filled = knn_filled_df[feature]\n",
    "\n",
    "    # Preserve original decimal precision or integer format\n",
    "    if is_int:\n",
    "        mean_filled = mean_filled.round(0).astype('Int64')\n",
    "        median_filled = median_filled.round(0).astype('Int64')\n",
    "        knn_filled = knn_filled.round(0).astype('Int64')\n",
    "    else:\n",
    "        mean_filled = mean_filled.round(decimal_places)\n",
    "        median_filled = median_filled.round(decimal_places)\n",
    "        knn_filled = knn_filled.round(decimal_places)\n",
    "\n",
    "    # Compare using Wasserstein distance\n",
    "    dists = {\n",
    "        'Mean': wasserstein_distance(original, mean_filled),\n",
    "        'Median': wasserstein_distance(original, median_filled),\n",
    "        'KNN': wasserstein_distance(original, knn_filled)\n",
    "    }\n",
    "    best_method = min(dists, key=dists.get)\n",
    "    best_methods[feature] = best_method\n",
    "\n",
    "    # Apply best imputation\n",
    "    if best_method == 'Mean':\n",
    "        if is_int:\n",
    "            value = round(imputed_df[feature].mean())\n",
    "            imputed_df[feature] = imputed_df[feature].fillna(value).astype('Int64')\n",
    "        else:\n",
    "            imputed_df[feature].fillna(imputed_df[feature].mean(), inplace=True)\n",
    "\n",
    "    elif best_method == 'Median':\n",
    "        if is_int:\n",
    "            value = round(imputed_df[feature].median())\n",
    "            imputed_df[feature] = imputed_df[feature].fillna(value).astype('Int64')\n",
    "        else:\n",
    "            imputed_df[feature].fillna(imputed_df[feature].median(), inplace=True)\n",
    "\n",
    "    elif best_method == 'KNN':\n",
    "        if is_int:\n",
    "            imputed_df[feature] = knn_filled.round(0).astype('Int64')\n",
    "        else:\n",
    "            imputed_df[feature] = knn_filled\n",
    "\n",
    "    # Plot distributions\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(3) \n",
    "    sns.kdeplot(original, label='Original (non-missing)', linewidth=4)\n",
    "    sns.kdeplot(mean_filled, label='Mean Imputation', linestyle='--', linewidth=3)\n",
    "    sns.kdeplot(median_filled, label='Median Imputation', linestyle='-.', linewidth=3)\n",
    "    sns.kdeplot(knn_filled, label='KNN Imputation', linestyle=':', linewidth=3)\n",
    "\n",
    "    plt.title(f\"{feature} - Distribution Comparison\\nBest Method: {best_method}\", fontweight='bold')\n",
    "    plt.xlabel(\"Value\", fontweight='bold')\n",
    "    plt.ylabel(\"Density\", fontweight='bold')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    # Save the plot\n",
    "    plot_filename = os.path.join(plot_dir, f\"{feature}_impute_compare.png\")\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()  # Close figure to avoid overlap\n",
    "\n",
    "\n",
    "# ========== Process All Selected Columns ========== #\n",
    "for col in to_impute_cols:\n",
    "    plot_distribution_comparison(col)\n",
    "\n",
    "# ========== Print Best Methods ========== #\n",
    "print(\"Best Imputation Method for Each Feature:\")\n",
    "for k, v in best_methods.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# Save best methods to CSV\n",
    "best_methods_df = pd.DataFrame(list(best_methods.items()), columns=[\"Feature\", \"Best_Imputation_Method\"])\n",
    "best_methods_df.to_csv(\"E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/impute_summary.csv\", index=False, encoding='utf-8-sig')    \n",
    "    \n",
    "# ========== Save Imputed Dataset ========== #\n",
    "output_path = \"E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_fill_en.csv\"\n",
    "imputed_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Imputed dataset saved to: {output_path}\")\n",
    "\n",
    "# ========== Show Info and Description ========== #\n",
    "print(\"\\nData Summary After Imputation:\")\n",
    "imputed_df.info()\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(imputed_df.describe())\n",
    "\n",
    "df_des=imputed_df.describe()\n",
    "df_des.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_fill_en_des.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad59ab",
   "metadata": {},
   "source": [
    "# 1.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from collections import Counter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'  \n",
    "plt.rcParams['font.size'] = 20                  \n",
    "plt.rcParams['font.weight'] = 'bold'            \n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['axes.labelweight'] = 'bold'        \n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.titleweight'] = 'bold'        \n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['legend.title_fontsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['axes.unicode_minus'] = False        \n",
    "\n",
    "# -----------------------------------------------\n",
    "# ---------- Association Calculation ----------\n",
    "# -----------------------------------------------\n",
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt((chi2 / n) / (min(k - 1, r - 1)))\n",
    "\n",
    "# -----------------------------------------------\n",
    "# ---------- Visualization Functions ----------\n",
    "# -----------------------------------------------\n",
    "def plot_heatmap(matrix, title, save_path=None):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    max_val = matrix.values[np.triu_indices_from(matrix, 1)].max()\n",
    "    sns.heatmap(matrix, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", square=True,\n",
    "                linewidths=0.5, cbar=True)\n",
    "    for y in range(matrix.shape[0]):\n",
    "        for x in range(matrix.shape[1]):\n",
    "            if matrix.iloc[y, x] == max_val and x != y:\n",
    "                plt.gca().add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor='red', lw=2))\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.xticks(rotation=45, fontweight='bold')\n",
    "    plt.yticks(rotation=0, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_heatmap_overlay(matrix, title, save_path=None):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "    max_val = matrix.values[np.triu_indices_from(matrix, 1)].max()\n",
    "    sns.heatmap(matrix, mask=mask, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", square=True,\n",
    "                linewidths=.5, cbar_kws={\"shrink\": .6}, alpha=0.9)\n",
    "    for y in range(matrix.shape[0]):\n",
    "        for x in range(matrix.shape[1]):\n",
    "            if matrix.iloc[y, x] == max_val and x != y and not mask[y, x]:\n",
    "                plt.gca().add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor='orange', lw=2))\n",
    "    plt.title(title + \" (Upper Triangle)\", fontsize=16, fontweight='bold')\n",
    "    plt.xticks(rotation=45, fontweight='bold')\n",
    "    plt.yticks(rotation=0, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_ringed_heatmap(matrix, title, save_path=None):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True,\n",
    "                linewidths=1, linecolor='white', cbar=False)\n",
    "    max_val = matrix.values[np.triu_indices_from(matrix, 1)].max()\n",
    "    for y in range(matrix.shape[0]):\n",
    "        for x in range(matrix.shape[1]):\n",
    "            value = matrix.iloc[y, x]\n",
    "            size = abs(value) * 500\n",
    "            color = 'red' if value == max_val and x != y else 'black'\n",
    "            ax.add_patch(plt.Circle((x+0.5, y+0.5), radius=0.15 + size/1500,\n",
    "                                    color=color, fill=False, lw=1.5))\n",
    "    plt.title(title + \" (Ring Enhanced)\", fontsize=16, fontweight='bold')\n",
    "    plt.xticks(rotation=45, fontweight='bold')\n",
    "    plt.yticks(rotation=0, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_cluster_heatmap(matrix, title, save_path=None, xtick_rotation=15):\n",
    "    \n",
    "    cg = sns.clustermap(matrix, cmap=\"PuBuGn\", annot=True, fmt=\".2f\",figsize=(10, 10), \n",
    "                        square=True, cbar_kws={\"shrink\": .6},dendrogram_ratio=(0.08, 0.08),cbar_pos=(0.009, 0.8, 0.03, 0.18))\n",
    "    \n",
    "    for ax in [cg.ax_row_dendrogram, cg.ax_col_dendrogram]:\n",
    "        for collection in ax.collections:\n",
    "            collection.set_linewidth(2)  \n",
    "        \n",
    "    plt.suptitle(title + \" (Clustered)\", fontsize=16, y=1.02, fontweight='bold')\n",
    "\n",
    "    cg.ax_heatmap.set_xticklabels(\n",
    "        cg.ax_heatmap.get_xticklabels(),\n",
    "        rotation=xtick_rotation,\n",
    "        ha='right',  \n",
    "    )\n",
    "\n",
    "    cg.ax_heatmap.set_yticklabels(\n",
    "        cg.ax_heatmap.get_yticklabels(),\n",
    "        rotation=-70\n",
    "    )\n",
    "\n",
    "    reordered_index = cg.data2d.index.tolist()\n",
    "\n",
    "    if 'LossType' in reordered_index:\n",
    "        row_pos = reordered_index.index('LossType')\n",
    "        ax = cg.ax_heatmap\n",
    "        ax.add_patch(Rectangle(\n",
    "            xy=(0, row_pos),          \n",
    "            width=matrix.shape[1],    \n",
    "            height=1,                 \n",
    "            fill=False,\n",
    "            edgecolor='red',\n",
    "            linewidth=4\n",
    "        ))\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=400, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_bubble_heatmap(matrix, title, save_path=None):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    max_val = matrix.values[np.triu_indices_from(matrix, 1)].max()\n",
    "    for y in range(matrix.shape[0]):\n",
    "        for x in range(matrix.shape[1]):\n",
    "            value = matrix.iloc[y, x]\n",
    "            edge_color = 'red' if value == max_val and x != y else 'k'\n",
    "            ax.scatter(x, y, s=value * 1500, c='skyblue', edgecolors=edge_color, alpha=0.7, linewidths=1.5)\n",
    "            ax.text(x, y, f\"{value:.2f}\", va='center', ha='center', fontsize=10)\n",
    "    ax.set_xticks(np.arange(len(matrix.columns)))\n",
    "    ax.set_yticks(np.arange(len(matrix.index)))\n",
    "    ax.set_xticklabels(matrix.columns, rotation=45, fontweight='bold')\n",
    "    ax.set_yticklabels(matrix.index, fontweight='bold')\n",
    "    ax.set_xlim(-0.5, len(matrix.columns) - 0.5)\n",
    "    ax.set_ylim(-0.5, len(matrix.index) - 0.5)\n",
    "    plt.title(title + \" (Bubble Heatmap)\", fontsize=16, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_fancy_diagonal_heatmap(matrix, title, save_path=None):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(matrix, annot=True, fmt=\".2f\", cmap=\"PuBuGn\", square=True,\n",
    "                linewidths=1, linecolor='white')\n",
    "    for i in range(len(matrix)):\n",
    "        plt.gca().add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor='red', lw=2))\n",
    "    plt.title(title + \" (Diagonal Highlighted)\", fontsize=16, fontweight='bold')\n",
    "    plt.xticks(rotation=45, fontweight='bold')\n",
    "    plt.yticks(rotation=0, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=400, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_3d_bar_heatmap(matrix, title, save_path=None):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    _x = np.arange(matrix.shape[0])\n",
    "    _y = np.arange(matrix.shape[1])\n",
    "    _xx, _yy = np.meshgrid(_x, _y)\n",
    "    x, y = _xx.ravel(), _yy.ravel()\n",
    "    top = matrix.values.ravel()\n",
    "    max_val = top.max()\n",
    "    colors = ['crimson' if v == max_val else 'steelblue' for v in top]\n",
    "    bottom = np.zeros_like(top)\n",
    "    width = depth = 0.8\n",
    "    ax.bar3d(x, y, bottom, width, depth, top, shade=True, color=colors)\n",
    "    ax.set_xticks(np.arange(len(matrix.columns)))\n",
    "    ax.set_xticklabels(matrix.columns, rotation=30, fontweight='bold')\n",
    "    ax.set_yticks(np.arange(len(matrix.index)))\n",
    "    ax.set_yticklabels(matrix.index, rotation=10,fontweight='bold')\n",
    "    ax.set_title(title + \" (3D Bar Chart)\", fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------\n",
    "# ---------- Main Process ----------\n",
    "# -----------------------------------------------\n",
    "# Load data\n",
    "data = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_fill_en.csv')\n",
    "#data = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_fill_en_IQR.csv')\n",
    "\n",
    "cat_cols = ['WorkingCondition', 'LossFormation', 'Lithology', 'LossSeverity', 'LossType']  # Consider translating column names if needed\n",
    "\n",
    "# Compute Cramér's V matrix\n",
    "cramer_matrix = pd.DataFrame(index=cat_cols, columns=cat_cols)\n",
    "for col1 in cat_cols:\n",
    "    for col2 in cat_cols:\n",
    "        cm = pd.crosstab(data[col1], data[col2])\n",
    "        cramer_matrix.loc[col1, col2] = cramers_v(cm)\n",
    "\n",
    "cramer_matrix = cramer_matrix.astype(float)\n",
    "path='E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/corr/'\n",
    "# ---------- Visualization: choose one ----------\n",
    "plot_heatmap(cramer_matrix, \"Cramér's V\", save_path=path+\"cramer_heatmap.png\")\n",
    "plot_heatmap_overlay(cramer_matrix, \"Cramér's V\", save_path=path+\"cramer_overlay.png\")\n",
    "plot_ringed_heatmap(cramer_matrix, \"Cramér's V\", save_path=path+\"cramer_ring.png\")\n",
    "plot_cluster_heatmap(cramer_matrix, \"Cramér's V\", save_path=path+\"cramer_cluster.png\")\n",
    "plot_bubble_heatmap(cramer_matrix, \"Cramér's V\", save_path=path+\"cramer_bubble.png\")\n",
    "plot_fancy_diagonal_heatmap(cramer_matrix, \"Cramér's V\", save_path=path+\"cramer_diagonal.png\")\n",
    "plot_3d_bar_heatmap(cramer_matrix, \"Cramér's V\", save_path=path+\"cramer_3dbar.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5a7938",
   "metadata": {},
   "source": [
    "# 2. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83405c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import font_manager\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score, roc_auc_score, precision_recall_curve, roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import itertools\n",
    "import os\n",
    "\n",
    "#\n",
    "font_path = 'C:/Users/mumu/AppData/Local/Microsoft/Windows/Fonts/SimHei.ttf'\n",
    "font_prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.sans-serif'] = [font_prop.get_name()]\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20                \n",
    "plt.rcParams['font.weight'] = 'bold'          \n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['axes.labelweight'] = 'bold'     \n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.titleweight'] = 'bold'     \n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['legend.title_fontsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['axes.unicode_minus'] = False     \n",
    "\n",
    "#\n",
    "def savefig_with_border(fig, axes, path, dpi=350):\n",
    "    if isinstance(axes, np.ndarray): \n",
    "        for ax in axes:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_linewidth(2)\n",
    "                spine.set_edgecolor('black')\n",
    "    else:  #\n",
    "        for spine in axes.spines.values():\n",
    "            spine.set_linewidth(2)\n",
    "            spine.set_edgecolor('black')\n",
    "    fig.savefig(path, dpi=dpi, bbox_inches='tight')\n",
    "\n",
    "        \n",
    "# \n",
    "encoded_data = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_enc_en.csv')\n",
    "raw_data = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_fill_en.csv')\n",
    "#encoded_data = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_enc_en_IQR.csv')\n",
    "#raw_data = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_fill_en_IQR.csv')\n",
    "\n",
    "X_encoded = encoded_data.drop(columns=['LossType'])\n",
    "y_encoded = encoded_data['LossType']\n",
    "\n",
    "X_raw = raw_data.drop(columns=['LossType'])\n",
    "y_raw = raw_data['LossType']\n",
    "\n",
    "cat_features = ['WorkingCondition','LossFormation','Lithology','LossSeverity']\n",
    "\n",
    "X_train_enc, X_test_enc, y_train_enc, y_test_enc = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=46)\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size=0.2, random_state=46)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_enc)\n",
    "X_test_scaled = scaler.transform(X_test_enc)\n",
    "\n",
    "lgb_model = LGBMClassifier(n_estimators=1000, learning_rate=0.05, random_state=46)\n",
    "lgb_model.fit(X_train_scaled, y_train_enc)\n",
    "lgb_train_pred = lgb_model.predict(X_train_scaled)\n",
    "lgb_test_pred = lgb_model.predict(X_test_scaled)\n",
    "\n",
    "label_map = {\n",
    "    '裂缝漏失': 'FractureLoss',\n",
    "    '断层漏失': 'FaultLoss',\n",
    "    '孔洞缝漏失': 'CavityFractureLoss',\n",
    "    '渗透性漏失': 'PermeabilityLoss'\n",
    "}\n",
    "y_train_raw=y_train_raw.map(label_map)\n",
    "y_test_raw=y_test_raw.map(label_map)\n",
    "catboost_model = CatBoostClassifier(    \n",
    "    iterations=300,\n",
    "    learning_rate=0.05,\n",
    "    depth=4,\n",
    "    random_state=46,\n",
    "    verbose=100,\n",
    "    loss_function='MultiClass',\n",
    "    task_type=\"GPU\",\n",
    "    devices='0',\n",
    "    early_stopping_rounds=50 \n",
    ")\n",
    "catboost_model.fit(X_train_raw, y_train_raw, cat_features=cat_features)\n",
    "cb_train_pred = catboost_model.predict(X_train_raw)\n",
    "cb_test_pred = catboost_model.predict(X_test_raw)\n",
    "\n",
    "def collect_metrics(name, y_train, y_train_pred, y_test, y_test_pred):\n",
    "    return [\n",
    "        {\n",
    "            \"Model\": name, \"Dataset\": \"Train\",\n",
    "            \"Accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "            \"Macro F1-score\": f1_score(y_train, y_train_pred, average='macro'),\n",
    "            \"Weighted F1-score\": f1_score(y_train, y_train_pred, average='weighted')\n",
    "        },\n",
    "        {\n",
    "            \"Model\": name, \"Dataset\": \"Test\",\n",
    "            \"Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "            \"Macro F1-score\": f1_score(y_test, y_test_pred, average='macro'),\n",
    "            \"Weighted F1-score\": f1_score(y_test, y_test_pred, average='weighted')\n",
    "        }\n",
    "    ]\n",
    "\n",
    "metrics = []\n",
    "metrics.extend(collect_metrics(\"LightGBM\", y_train_enc, lgb_train_pred, y_test_enc, lgb_test_pred))\n",
    "metrics.extend(collect_metrics(\"CatBoost\", y_train_raw, cb_train_pred, y_test_raw, cb_test_pred))\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(12, 7))\n",
    "sns.barplot(data=metrics_df, x=\"Model\", y=\"Accuracy\", hue=\"Dataset\", palette=\"Set2\", edgecolor='black',ax=ax)\n",
    "plt.title(\"Accuracy Comparison Between Train and Test Sets\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height>0:\n",
    "        ax.annotate(f\"{height:.2%}\", (p.get_x() + p.get_width() / 2., height),ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model/Accuracy-compare.png',dpi=400, bbox_inches='tight')\n",
    "#set_axes_border(ax)\n",
    "savefig_with_border(fig,ax,'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model/Accuracy-compare.png')\n",
    "plt.show()\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(12, 7))\n",
    "sns.barplot(data=metrics_df, x=\"Model\", y=\"Macro F1-score\", hue=\"Dataset\", palette=\"Set1\", edgecolor='black',ax=ax)\n",
    "plt.title(\"Macro F1-score Comparison Between Train and Test Sets\")\n",
    "plt.ylabel(\"Macro F1-score\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:\n",
    "        ax.annotate(f\"{height:.2%}\", (p.get_x() + p.get_width() / 2., height),\n",
    "                    ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model/Macro F1-score-compare.png', dpi=400, bbox_inches='tight')\n",
    "#set_axes_border(ax)\n",
    "savefig_with_border(fig,ax,'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model/Macro F1-score-compare.png')\n",
    "plt.show()\n",
    "\n",
    "#plt.figure(figsize=(12, 6))\n",
    "fig,ax=plt.subplots(figsize=(12, 7))\n",
    "sns.barplot(data=metrics_df, x=\"Model\", y=\"Weighted F1-score\", hue=\"Dataset\", palette=\"Set3\", edgecolor='black',ax=ax)\n",
    "plt.title(\"Weighted F1-score Comparison Between Train and Test Sets\")\n",
    "plt.ylabel(\"Weighted F1-score\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:\n",
    "        ax.annotate(f\"{height:.2%}\", (p.get_x() + p.get_width() / 2., height),\n",
    "                    ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model/Weighted F1-score-compare.png', dpi=400, bbox_inches='tight')\n",
    "#set_axes_border(ax)\n",
    "savefig_with_border(fig,ax,'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model/Weighted F1-score-compare.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"LightGBM Classification Report：\")\n",
    "print(classification_report(y_test_enc, lgb_test_pred))\n",
    "\n",
    "print(\"CatBoost Classification Report：\")\n",
    "print(classification_report(y_test_raw, cb_test_pred))\n",
    "\n",
    "def plot_train_test_confusion_side_by_side(models_preds_train, models_preds_test, y_trues_train, y_trues_test, labels, model_names, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for i, name in enumerate(model_names):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "        cm_train = confusion_matrix(y_trues_train[i], models_preds_train[i])\n",
    "        disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=labels)\n",
    "        disp_train.plot(ax=axes[0], cmap='Blues', values_format='d')\n",
    "        axes[0].set_title(f'{name} - Train',fontsize=24)\n",
    "        axes[0].set_xlabel(\"Predicted Label\", fontsize=24, labelpad=10)\n",
    "        axes[0].set_ylabel(\"True Label\", fontsize=24, labelpad=10)\n",
    "        axes[0].tick_params(axis='x', labelrotation=20, labelsize=22)\n",
    "        axes[0].tick_params(axis='y', labelrotation=20, labelsize=22)\n",
    "\n",
    "        cm_test = confusion_matrix(y_trues_test[i], models_preds_test[i])\n",
    "        disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=labels)\n",
    "        disp_test.plot(ax=axes[1], cmap='Blues', values_format='d')\n",
    "        axes[1].set_title(f'{name} - Test',fontsize=24)\n",
    "        axes[1].set_xlabel(\"Predicted Label\", fontsize=24, labelpad=10)\n",
    "        axes[1].set_ylabel(\"True Label\", fontsize=24, labelpad=10)\n",
    "        axes[1].tick_params(axis='x', labelrotation=20, labelsize=22)\n",
    "        axes[1].tick_params(axis='y', labelrotation=20, labelsize=22)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(f'{save_dir}/confusion_matrix_{name}.png', dpi=450, bbox_inches='tight')\n",
    "        #for ax in axes:\n",
    "        #    set_axes_border(ax)\n",
    "        savefig_with_border(fig,axes,f'{save_dir}/confusion_matrix_{name}.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "class_names = ['FractureLoss', 'FaultLoss', 'CavityFractureLoss', 'PermeabilityLoss']\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "code_to_label = {0: 'FractureLoss', 1: 'FaultLoss', 2: 'CavityFractureLoss', 3: 'PermeabilityLoss'}\n",
    "def decode_labels(encoded_list):\n",
    "    return [code_to_label[i] for i in encoded_list]\n",
    "models_preds_train_labels = [\n",
    "    decode_labels(lgb_train_pred),\n",
    "    list(cb_train_pred)\n",
    "]\n",
    "models_preds_test_labels = [\n",
    "    decode_labels(lgb_test_pred),\n",
    "    list(cb_test_pred)\n",
    "]\n",
    "\n",
    "y_train_enc_labels = [code_to_label[i] for i in y_train_enc]\n",
    "y_test_enc_labels = [code_to_label[i] for i in y_test_enc]\n",
    "plot_train_test_confusion_side_by_side(\n",
    "    models_preds_train=models_preds_train_labels,\n",
    "    models_preds_test=models_preds_test_labels,\n",
    "    y_trues_train=[y_train_enc_labels, y_train_enc_labels, list(y_train_raw)],\n",
    "    y_trues_test=[y_test_enc_labels, y_test_enc_labels, list(y_test_raw)],\n",
    "    labels=list(code_to_label.values()),\n",
    "    model_names=['LightGBM','CatBoost'],\n",
    "    save_dir='E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model'\n",
    ")\n",
    "\n",
    "def plot_multi_class_roc(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    classes = np.unique(np.concatenate([y_train, y_test]))\n",
    "    y_train_bin = label_binarize(y_train, classes=classes)\n",
    "    y_test_bin = label_binarize(y_test, classes=classes)\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    def safe_predict_proba(m, X, name):\n",
    "        if name == 'CatBoost':\n",
    "            proba = np.array(m.predict_proba(X))\n",
    "        else:\n",
    "            proba = m.predict_proba(X)\n",
    "        if isinstance(proba, list):\n",
    "            proba = np.array(proba)\n",
    "        return np.squeeze(proba)\n",
    "\n",
    "    y_score_train = safe_predict_proba(model, X_train, model_name)\n",
    "    y_score_test = safe_predict_proba(model, X_test, model_name)\n",
    "\n",
    "    colors = plt.cm.tab10.colors\n",
    "    fig,ax=plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    for j in range(n_classes):\n",
    "        if len(np.unique(y_train_bin[:, j])) >= 2:\n",
    "            fpr_train, tpr_train, _ = roc_curve(y_train_bin[:, j], y_score_train[:, j])\n",
    "            auc_train = auc(fpr_train, tpr_train)\n",
    "            plt.plot(fpr_train, tpr_train, linestyle='-', color=colors[j % len(colors)],\n",
    "                     label=f'Train - Class {classes[j]} (AUC={auc_train:.2f})')\n",
    "\n",
    "        if len(np.unique(y_test_bin[:, j])) >= 2:\n",
    "            fpr_test, tpr_test, _ = roc_curve(y_test_bin[:, j], y_score_test[:, j])\n",
    "            auc_test = auc(fpr_test, tpr_test)\n",
    "            plt.plot(fpr_test, tpr_test, linestyle='--', color=colors[j % len(colors)],\n",
    "                     label=f'Test - Class {classes[j]} (AUC={auc_test:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate(FPR)')\n",
    "    plt.ylabel('True Positive Rate(TPR)')\n",
    "    plt.title(f'Mulit-Classification ROC Curve (Train vs Test) of {model_name} ')\n",
    "    plt.legend(loc=\"lower right\", fontsize='small')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model/roc-{model_name}.png',dpi=350, bbox_inches='tight')\n",
    "    #set_axes_border()\n",
    "    savefig_with_border(fig,ax,f'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model/roc-{model_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_catboost_roc_compare(\n",
    "    y_train, y_train_prob,\n",
    "    y_test, y_test_prob,\n",
    "    class_names, \n",
    "    title=\"Mulit-Classification ROC Curve (Train vs Test) of CatBoost\", \n",
    "    figsize=(10, 8)):\n",
    "    n_classes = len(class_names)\n",
    "    y_train_bin = label_binarize(y_train, classes=class_names)\n",
    "    y_test_bin = label_binarize(y_test, classes=class_names)\n",
    "\n",
    "    fpr_train, tpr_train, auc_train = {}, {}, {}\n",
    "    fpr_test, tpr_test, auc_test = {}, {}, {}\n",
    "\n",
    "    #plt.figure(figsize=figsize)\n",
    "    fig,ax=plt.subplots(figsize=figsize)\n",
    "    colors = plt.cm.tab10.colors\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr_train[i], tpr_train[i], _ = roc_curve(y_train_bin[:, i], y_train_prob[:, i])\n",
    "        auc_train[i] = auc(fpr_train[i], tpr_train[i])\n",
    "        plt.plot(fpr_train[i], tpr_train[i], linestyle='--', color=colors[i % len(colors)],\n",
    "                 label=f\"Train - Class {class_names[i]} (AUC={auc_train[i]:.2f})\")\n",
    "\n",
    "        fpr_test[i], tpr_test[i], _ = roc_curve(y_test_bin[:, i], y_test_prob[:, i])\n",
    "        auc_test[i] = auc(fpr_test[i], tpr_test[i])\n",
    "        plt.plot(fpr_test[i], tpr_test[i], linestyle='-', color=colors[i % len(colors)],\n",
    "                 label=f\"Test  - Class {class_names[i]} (AUC={auc_test[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='lower right', fontsize='small')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model/roc-catboost.png',dpi=350, bbox_inches='tight')\n",
    "    #set_axes_border()\n",
    "    savefig_with_border(fig,ax,'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/model/roc-catboost.png')\n",
    "    plt.show()\n",
    "    \n",
    "plot_multi_class_roc(lgb_model, X_train_scaled, y_train_enc_labels, X_test_scaled, y_test_enc_labels, \"LightGBM\")\n",
    "y_prob_train_cb = catboost_model.predict_proba(X_train_raw)\n",
    "y_prob_test_cb = catboost_model.predict_proba(X_test_raw)\n",
    "class_names = np.unique(np.concatenate([y_train_raw, y_test_raw]))\n",
    "plot_catboost_roc_compare(\n",
    "    y_train=y_train_raw,\n",
    "    y_train_prob=y_prob_train_cb,\n",
    "    y_test=y_test_raw,\n",
    "    y_test_prob=y_prob_test_cb,\n",
    "    class_names=class_names,\n",
    "    title=\"Mulit-Classification ROC Curve (Train vs Test) of CatBoost\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f5e4f",
   "metadata": {},
   "source": [
    "# 3. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "model = catboost_model\n",
    "model.fit(X_train_raw, y_train_raw, cat_features=cat_features)\n",
    "\n",
    "y_pred_train_cb = model.predict(X_train_raw)\n",
    "y_prob_train_cb = model.predict_proba(X_train_raw)\n",
    "y_pred_test_cb = model.predict(X_test_raw)\n",
    "y_prob_test_cb = model.predict_proba(X_test_raw)\n",
    "\n",
    "print(\"== Trainset Classification_report ==\")\n",
    "print(metrics.classification_report(y_train_raw, y_pred_train_cb, digits=3))\n",
    "\n",
    "print(\"== Trainset Indicators ==\")\n",
    "print(\"Accuracy score   :\", accuracy_score(y_train_raw, y_pred_train_cb))\n",
    "print(\"Precision (macro):\", precision_score(y_train_raw, y_pred_train_cb, average='macro'))\n",
    "print(\"Recall    (macro):\", recall_score(y_train_raw, y_pred_train_cb, average='macro'))\n",
    "print(\"F1-score  (macro):\", f1_score(y_train_raw, y_pred_train_cb, average='macro'))\n",
    "\n",
    "print(\"Precision (micro):\", precision_score(y_train_raw, y_pred_train_cb, average='micro'))\n",
    "print(\"Recall    (micro):\", recall_score(y_train_raw, y_pred_train_cb, average='micro'))\n",
    "print(\"F1-score  (micro):\", f1_score(y_train_raw, y_pred_train_cb, average='micro'))\n",
    "print(\"F1-score  (weighted):\", f1_score(y_train_raw, y_pred_train_cb, average='weighted'))\n",
    "\n",
    "try:\n",
    "    print(\"ROC AUC (ovr)    :\", roc_auc_score(y_train_raw, y_prob_train_cb, multi_class='ovr'))\n",
    "except ValueError:\n",
    "    print(\"ROC AUC skipped (need predict_proba and all classes present)\")\n",
    "\n",
    "print(\"\\n== Testset Classification_report ==\")\n",
    "print(metrics.classification_report(y_test_raw, y_pred_test_cb, digits=3))\n",
    "\n",
    "print(\"== Testset Indicators ==\")\n",
    "print(\"Accuracy score   :\", accuracy_score(y_test_raw, y_pred_test_cb))\n",
    "print(\"Precision (macro):\", precision_score(y_test_raw, y_pred_test_cb, average='macro'))\n",
    "print(\"Recall    (macro):\", recall_score(y_test_raw, y_pred_test_cb, average='macro'))\n",
    "print(\"F1-score  (macro):\", f1_score(y_test_raw, y_pred_test_cb, average='macro'))\n",
    "\n",
    "print(\"Precision (micro):\", precision_score(y_test_raw, y_pred_test_cb, average='micro'))\n",
    "print(\"Recall    (micro):\", recall_score(y_test_raw, y_pred_test_cb, average='micro'))\n",
    "print(\"F1-score  (micro):\", f1_score(y_test_raw, y_pred_test_cb, average='micro'))\n",
    "print(\"F1-score  (weighted):\", f1_score(y_test_raw, y_pred_test_cb, average='weighted'))\n",
    "try:\n",
    "    print(\"ROC AUC (ovr)    :\", roc_auc_score(y_test_raw, y_prob_test_cb, multi_class='ovr'))\n",
    "except ValueError:\n",
    "    print(\"ROC AUC skipped (need predict_proba and all classes present)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e10f5a",
   "metadata": {},
   "source": [
    "# 4. SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063be908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'  \n",
    "plt.rcParams['font.size'] = 20                  \n",
    "plt.rcParams['font.weight'] = 'bold'            \n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['axes.labelweight'] = 'bold'        \n",
    "plt.rcParams['axes.titlesize'] = 24\n",
    "plt.rcParams['axes.titleweight'] = 'bold'        \n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['legend.title_fontsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['axes.unicode_minus'] = False       \n",
    "\n",
    "csv_path = 'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_fill_en.csv'\n",
    "#csv_path = 'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_fill_en_IQR.csv'\n",
    "target_column = 'LossType'  \n",
    "categorical_features = ['WorkingCondition', 'LossFormation', 'Lithology', 'LossSeverity']\n",
    "sampling_ratio = 0.7 \n",
    "\n",
    "save_dir = 'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/smotenc/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "loss_type_mapping = {\n",
    "    '裂缝漏失': 'FractureLoss',\n",
    "    '断层漏失': 'FaultLoss',\n",
    "    '孔洞缝漏失': 'CavityFractureLoss',\n",
    "    '渗透性漏失': 'PermeabilityLoss'\n",
    "}\n",
    "df[target_column] = df[target_column].map(loss_type_mapping)\n",
    "\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "X_encoded = X.copy()\n",
    "encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "class_counts = Counter(y)\n",
    "print(\"原始类别分布：\", class_counts)\n",
    "max_count = max(class_counts.values())\n",
    "target_count = int(max_count * sampling_ratio)\n",
    "sampling_strategy = {cls: target_count for cls, count in class_counts.items() if count < target_count}\n",
    "print(\"生成的 sampling_strategy:\", sampling_strategy)\n",
    "\n",
    "cat_feature_indices = [X.columns.get_loc(col) for col in categorical_features]\n",
    "smote_nc = SMOTENC(categorical_features=cat_feature_indices, \n",
    "                   sampling_strategy=sampling_strategy, \n",
    "                   k_neighbors=3,\n",
    "                   random_state=42,\n",
    "                   n_jobs=-1)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X_encoded, y)\n",
    "\n",
    "df_orig = pd.DataFrame({'Class': y, 'Dataset': 'Original'})\n",
    "df_resampled = pd.DataFrame({'Class': y_resampled, 'Dataset': 'Resampled'})\n",
    "df_all = pd.concat([df_orig, df_resampled], ignore_index=True)\n",
    "df_all['Class'] = df_all['Class'].astype(str)\n",
    "desired_order = ['FractureLoss', 'FaultLoss', 'CavityFractureLoss', 'PermeabilityLoss']\n",
    "\n",
    "plt.figure(figsize=(13, 8))\n",
    "ax = sns.countplot(data=df_all, x='Class', hue='Dataset',order=desired_order, edgecolor='black')\n",
    "plt.title('Class Distribution Comparison: Original vs Resampled')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=10,fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "ax.legend(loc='upper right',title='Dataset')\n",
    "for patch in ax.patches:\n",
    "    height = patch.get_height()\n",
    "    if height>0:\n",
    "        ax.text(patch.get_x() + patch.get_width() / 2, height + 1, int(height), ha='center', va='bottom')\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "    spine.set_edgecolor('black')\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/smotenc/comparison_losstype.png',dpi=350,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "if not isinstance(X_resampled, pd.DataFrame):\n",
    "    X_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    \n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in numeric_cols:\n",
    "    #plt.figure(figsize=(12, 6))\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sns.kdeplot(data=X[col], label='Original', fill=True, alpha=0.4, linewidth=2,ax=ax)\n",
    "    sns.kdeplot(data=X_resampled[col], label='Resampled', fill=True, alpha=0.4, linewidth=2,ax=ax)\n",
    "    plt.title(f'Distribution Comparison: {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2)\n",
    "        spine.set_edgecolor('black')\n",
    "    filename = f\"{save_dir}kde_{col}.png\"\n",
    "    plt.savefig(filename, dpi=350,bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_categorical_comparison_english(column_name, df_orig, df_resampled, mapping_dict):\n",
    "    df_orig_ = df_orig[[column_name]].copy()\n",
    "    df_orig_['Source'] = 'Original'\n",
    "    df_res_ = df_resampled[[column_name]].copy()\n",
    "    df_res_['Source'] = 'Resampled'\n",
    "    df_all = pd.concat([df_orig_, df_res_], axis=0)\n",
    "    df_all['EnglishLabel'] = df_all[column_name].map(mapping_dict)\n",
    "\n",
    "    if column_name in ['LossFormation']:\n",
    "        figsize = (15, 8)\n",
    "        rotation = 40\n",
    "        fontsize = 18\n",
    "        ha = 'right'\n",
    "    elif column_name in ['WorkingCondition']:  \n",
    "        figsize = (12, 8)\n",
    "        rotation = 30\n",
    "        fontsize = 18\n",
    "        ha = 'right'\n",
    "    else : \n",
    "        figsize = (12, 8)\n",
    "        rotation = 0\n",
    "        fontsize = 18\n",
    "        ha = 'center'\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.countplot(data=df_all, x='EnglishLabel', hue='Source')\n",
    "\n",
    "    plt.title(f'Distribution Comparison of {column_name}')\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.xticks(rotation=rotation, ha=ha, fontsize=fontsize)\n",
    "\n",
    "    plt.legend(title='Dataset', fontsize=17, title_fontsize=18)\n",
    "\n",
    "    for patch in ax.patches:\n",
    "        height = patch.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(patch.get_x() + patch.get_width()/2, height + 1, int(height), ha='center', va='bottom', fontsize=17)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2)\n",
    "        spine.set_edgecolor('black')\n",
    "\n",
    "    filename = os.path.join(save_dir, f'cat_comparison_{column_name}.png')\n",
    "    plt.savefig(filename, dpi=350, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "X_resampled_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "for col in categorical_features:\n",
    "    le = encoders[col]\n",
    "    X_resampled_df[col] = le.inverse_transform(X_resampled_df[col].astype(int))\n",
    "\n",
    "numerical_features=[col for col in X.columns if col not in categorical_features]\n",
    "X_resampled[numerical_features]=X_resampled[numerical_features].round(2)\n",
    "int_columns=X.select_dtypes(include=['int64']).columns\n",
    "int_columns=[col for col in int_columns if col not in categorical_features]\n",
    "X_resampled_df[int_columns] = X_resampled_df[int_columns].round().astype(int)\n",
    "\n",
    "working_condition_map = {\n",
    "    '注水泥': 'Cementing', '划眼': 'Reaming', '钻进': 'Drilling', '倒划眼': 'BackReaming',\n",
    "    '循环': 'Circulation', '压井': 'WellKilling', '下套管': 'RunningCasing', '注水泥堵漏': 'CementPlugging',\n",
    "    '堵漏': 'LossControl', '下钻': 'RunInHole', '起钻': 'PullOutHole', '固井前循环': 'PreCementCirculation',\n",
    "    '测井': 'Logging', '地漏试验': 'LeakageTest'\n",
    "}\n",
    "loss_formation_map = {\n",
    "    '东二上段': 'Dong2_Upper', '古生界': 'Paleozoic', '东二下段': 'Dong2_Lower', '中生界': 'Mesozoic',\n",
    "    '东一段': 'Dong1', '馆陶组': 'Guantao', '东三段': 'Dong3', '孔店组': 'Kongdian',\n",
    "    '太古界': 'Archean', '明化镇': 'Minghuazhen', '东二段': 'Dong2', '沙一段': 'Sha1',\n",
    "    '潜山': 'Qianshan', '沙二段': 'Sha2', '沙三段': 'Sha3', '东营组': 'Dongying',\n",
    "    '东上段': 'Dong_Upper', '东下段': 'Dong_Lower', '沙河街': 'Shahejie', '明下段': 'Ming_Lower',\n",
    "    '明上段': 'Ming_Upper', '平原组': 'Pingyuan', '沙四段': 'Sha4', '沙三中段': 'Sha3_Mid',\n",
    "    '沙三下': 'Sha3_Lower'\n",
    "}\n",
    "lithology_map = {\n",
    "    '泥岩': 'Mudstone', '灰岩': 'Limestone', '砂岩': 'Sandstone', '火成岩': 'Igneous',\n",
    "    '砾岩': 'Conglomerate', '变质岩': 'Metamorphic'\n",
    "}\n",
    "loss_severity_map = {\n",
    "    '严重井漏': 'SevereLoss', '微漏': 'MinorLoss', '中漏': 'ModerateLoss', '小漏': 'SlightLoss'\n",
    "}\n",
    "\n",
    "mapping_dicts = {\n",
    "    'WorkingCondition': working_condition_map,\n",
    "    'LossFormation': loss_formation_map,\n",
    "    'Lithology': lithology_map,\n",
    "    'LossSeverity': loss_severity_map\n",
    "}\n",
    "\n",
    "for col in categorical_features:\n",
    "    plot_categorical_comparison_english(col, X, X_resampled_df, mapping_dicts[col])\n",
    "\n",
    "resampled_data = pd.concat([X_resampled_df.reset_index(drop=True),\n",
    "                            pd.Series(y_resampled, name=target_column).reset_index(drop=True)], axis=1)\n",
    "\n",
    "resampled_csv_path = 'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/data/leakage_type_selected_fill_en_resampled.csv'\n",
    "resampled_data.to_csv(resampled_csv_path, index=False, encoding='utf-8-sig')\n",
    "print(f'采样后数据已保存至：{resampled_csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa74415",
   "metadata": {},
   "source": [
    "# 5. SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd8f83",
   "metadata": {},
   "source": [
    "# 5.1 Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02005a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "plt.rcParams['font.family'] = 'Times New Roman'  \n",
    "plt.rcParams['font.size'] = 20                  \n",
    "plt.rcParams['font.weight'] = 'bold'           \n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['axes.labelweight'] = 'bold'       \n",
    "plt.rcParams['axes.titlesize'] = 24\n",
    "plt.rcParams['axes.titleweight'] = 'bold'        \n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['legend.title_fontsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['axes.unicode_minus'] = False        \n",
    "\n",
    "def savefig_with_border(fig, axes, path, dpi=350):\n",
    "    if isinstance(axes, np.ndarray):\n",
    "        for ax in axes:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_linewidth(2)\n",
    "                spine.set_edgecolor('black')\n",
    "    else:  \n",
    "        for spine in axes.spines.values():\n",
    "            spine.set_linewidth(2)\n",
    "            spine.set_edgecolor('black')\n",
    "    fig.savefig(path, dpi=dpi, bbox_inches='tight')\n",
    "\n",
    "explainer=shap.TreeExplainer(model)\n",
    "shap_values=explainer.shap_values(X_test_raw)\n",
    "\n",
    "mean_abs_shap = np.mean(np.abs(shap_values), axis=2)  # shape: (samples, features)\n",
    "\n",
    "feature_importance = np.mean(mean_abs_shap, axis=0)  # shape: (features,)\n",
    "feature_names = X_test_raw.columns\n",
    "\n",
    "shap_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'SHAP Importance': feature_importance\n",
    "}).sort_values(by='SHAP Importance', ascending=False)\n",
    "\n",
    "top_n = 30\n",
    "shap_df_top = shap_df.head(top_n)\n",
    "#plt.figure(figsize=(10, 8))\n",
    "fig,ax=plt.subplots(figsize=(13,9))\n",
    "bars = plt.barh(\n",
    "    shap_df_top['Feature'][::-1], \n",
    "    shap_df_top['SHAP Importance'][::-1],\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.001, bar.get_y() + bar.get_height() / 2,\n",
    "             f'{width:.4f}', va='center', fontsize=17)\n",
    "\n",
    "plt.xlabel(\"Mean SHAP Value (|impact|)\")\n",
    "plt.title(\"SHAP Feature Importance (All Classes Averaged)\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/shap/overall_bar_with_values.png', dpi=350)\n",
    "savefig_with_border(fig,ax,'E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/shap/overall_bar_with_values.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea8cee",
   "metadata": {},
   "source": [
    "# 5.2 Class-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698fee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "plt.rcParams['font.family'] = 'Times New Roman'  \n",
    "plt.rcParams['font.size'] = 20                  \n",
    "plt.rcParams['font.weight'] = 'bold'           \n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['axes.labelweight'] = 'bold'      \n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['axes.titleweight'] = 'bold'       \n",
    "plt.rcParams['legend.fontsize'] = 20\n",
    "plt.rcParams['legend.title_fontsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['axes.unicode_minus'] = False        \n",
    "\n",
    "def savefig_with_border(fig, axes, path, dpi=350):\n",
    "    if isinstance(axes, np.ndarray):  \n",
    "        for ax in axes:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_linewidth(2)\n",
    "                spine.set_edgecolor('black')\n",
    "    else:  \n",
    "        for spine in axes.spines.values():\n",
    "            spine.set_linewidth(2)\n",
    "            spine.set_edgecolor('black')\n",
    "    fig.savefig(path, dpi=dpi, bbox_inches='tight')\n",
    "\n",
    "print(pd.Series(y_test_raw).unique())\n",
    "\n",
    "def custom_colormap():\n",
    "    return plt.cm.viridis\n",
    "\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\"blue_red\", [\"blue\", \"red\"])\n",
    "\n",
    "def add_legend():\n",
    "    plt.scatter([], [], color='gray', label='Character Variables', s=100)\n",
    "    plt.scatter([], [], color='red', label='Positive Impact', s=100)\n",
    "    plt.scatter([], [], color='blue', label='Negative Impact', s=100)\n",
    "    plt.legend(loc='upper center', fontsize=15,bbox_to_anchor=(0.4, -0.05), ncol=3, frameon=False)\n",
    "\n",
    "shap_values_class_0 = shap_values[:, :, 0]\n",
    "shap.summary_plot(shap_values_class_0, X_test_raw, show=False, max_display=len(X_test_raw.columns))\n",
    "plt.suptitle(\"SHAP Summary Plot for FaultLoss\",fontsize=20,fontweight='bold')\n",
    "plt.subplots_adjust(top=0.94)\n",
    "add_legend()\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/shap/faultloss.png',dpi=350,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "shap_values_class_1 = shap_values[:, :, 1] \n",
    "shap.summary_plot(shap_values_class_1, X_test_raw, show=False, max_display=len(X_test_raw.columns))\n",
    "plt.suptitle(\"SHAP Summary Plot for FractureLoss\",fontsize=20,fontweight='bold')\n",
    "plt.subplots_adjust(top=0.94) \n",
    "add_legend()\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/shap/fractureloss.png',dpi=350,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "shap_values_class_2 = shap_values[:, :, 2]\n",
    "shap.summary_plot(shap_values_class_2, X_test_raw, show=False, max_display=len(X_test_raw.columns))\n",
    "plt.suptitle(\"SHAP Summary Plot for PermeabilityLoss\",fontsize=20,fontweight='bold')\n",
    "plt.subplots_adjust(top=0.94)\n",
    "add_legend()\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/shap/permeabilityloss.png',dpi=350,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "shap_values_class_3 = shap_values[:, :, 3]\n",
    "shap.summary_plot(shap_values_class_3, X_test_raw, show=False, max_display=len(X_test_raw.columns))\n",
    "plt.suptitle(\"SHAP Summary Plot for CavityFractureLoss\",fontsize=20,fontweight='bold')\n",
    "plt.subplots_adjust(top=0.94)\n",
    "add_legend()\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/shap/cavityfractureloss.png',dpi=350,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3a2a3",
   "metadata": {},
   "source": [
    "# 5.3 Sample-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 映射字典 ---\n",
    "working_condition_map = {\n",
    "    '注水泥': 'Cementing', '划眼': 'Reaming', '钻进': 'Drilling', '倒划眼': 'BackReaming',\n",
    "    '循环': 'Circulation', '压井': 'WellKilling', '下套管': 'RunningCasing', '注水泥堵漏': 'CementPlugging',\n",
    "    '堵漏': 'LossControl', '下钻': 'RunInHole', '起钻': 'PullOutHole', '固井前循环': 'PreCementCirculation',\n",
    "    '测井': 'Logging', '地漏试验': 'LeakageTest'\n",
    "}\n",
    "loss_formation_map = {\n",
    "    '东二上段': 'Dong2_Upper', '古生界': 'Paleozoic', '东二下段': 'Dong2_Lower', '中生界': 'Mesozoic',\n",
    "    '东一段': 'Dong1', '馆陶组': 'Guantao', '东三段': 'Dong3', '孔店组': 'Kongdian',\n",
    "    '太古界': 'Archean', '明化镇': 'Minghuazhen', '东二段': 'Dong2', '沙一段': 'Sha1',\n",
    "    '潜山': 'Qianshan', '沙二段': 'Sha2', '沙三段': 'Sha3', '东营组': 'Dongying',\n",
    "    '东上段': 'Dong_Upper', '东下段': 'Dong_Lower', '沙河街': 'Shahejie', '明下段': 'Ming_Lower',\n",
    "    '明上段': 'Ming_Upper', '平原组': 'Pingyuan', '沙四段': 'Sha4', '沙三中段': 'Sha3_Mid',\n",
    "    '沙三下': 'Sha3_Lower'\n",
    "}\n",
    "lithology_map = {\n",
    "    '泥岩': 'Mudstone', '灰岩': 'Limestone', '砂岩': 'Sandstone', '火成岩': 'Igneous',\n",
    "    '砾岩': 'Conglomerate', '变质岩': 'Metamorphic'\n",
    "}\n",
    "loss_severity_map = {\n",
    "    '严重井漏': 'SevereLoss', '微漏': 'MinorLoss', '中漏': 'ModerateLoss', '小漏': 'SlightLoss'\n",
    "}\n",
    "\n",
    "mapping_dicts = {\n",
    "    'WorkingCondition': working_condition_map,\n",
    "    'LossFormation': loss_formation_map,\n",
    "    'Lithology': lithology_map,\n",
    "    'LossSeverity': loss_severity_map\n",
    "}\n",
    "\n",
    "def map_and_fill(df, mapping_dicts, fill_na_value='Unknown'):\n",
    "    for col, mapping in mapping_dicts.items():\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(mapping)\n",
    "            df[col] = df[col].fillna(fill_na_value)\n",
    "    return df\n",
    "\n",
    "X_test_mapped = map_and_fill(X_test_raw.copy(), mapping_dicts)\n",
    "print('shap_values shape:', shap_values.shape)\n",
    "print('X_test_mapped shape:', X_test_mapped.shape)\n",
    "\n",
    "class_names=['FaultLoss','FractureLoss','PermeabilityLoss','CavityFractureLoss']\n",
    "sample_index = 9\n",
    "class_index = 0\n",
    "num_features = X_test_mapped.shape[1] \n",
    "for class_index in range(shap_values.shape[2]):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    shap.decision_plot(\n",
    "        explainer.expected_value[class_index],\n",
    "        shap_values[:, :, class_index][sample_index:sample_index+1],\n",
    "        features=X_test_mapped.iloc[sample_index:sample_index+1],\n",
    "        feature_names=X_test_mapped.columns.tolist(),\n",
    "        feature_order='none',\n",
    "        #max_display=num_features\n",
    "    )\n",
    "    fig.suptitle(f\"Sample {sample_index} - Decision Plot for {class_names[class_index]}\",fontsize=20,fontweight='bold')\n",
    "    fig.savefig(f\"E:/jupyter/lost_circulation/records/paper-bhyt/leakage_type/thesis/En/picture/shap/decision_plot_sample{sample_index}_class{class_index}.png\", bbox_inches='tight', dpi=350)\n",
    "    plt.close(fig)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acac206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
